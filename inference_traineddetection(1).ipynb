{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8945766f",
   "metadata": {
    "id": "7cc9a687"
   },
   "source": [
    "![alt](https://research.utm.my/wp-content/uploads/sites/26/2022/06/logo-300x122.png)\n",
    "# Center for Artificial Intelligence and Robotics\n",
    "#### Universiti Teknologi Malaysia\n",
    "\n",
    "\n",
    "### Detection Inference - FasterRCNN\n",
    "\n",
    "*Author: Dr. Ibrahim, Azzam, Thaqif & Syahmi*\n",
    "\n",
    "**FasterRCNN for object detection.**\n",
    "\n",
    "_ | _"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999c9f1f",
   "metadata": {
    "id": "e24c6230"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models.detection import fasterrcnn_resnet50_fpn\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "import requests\n",
    "\n",
    "# URL to the COCO class names\n",
    "url = 'https://raw.githubusercontent.com/amikelive/coco-labels/master/coco-labels-paper.txt'\n",
    "\n",
    "# Download the class names\n",
    "response = requests.get(url)\n",
    "coco_classes = ['background'] + response.text.strip().split('\\n')\n",
    "\n",
    "# Load the Faster R-CNN model pre-trained on COCO dataset\n",
    "model = fasterrcnn_resnet50_fpn(pretrained=True)\n",
    "model.eval()\n",
    "\n",
    "# Load an image\n",
    "image_path = 'test_images/cat.jpg'\n",
    "image = Image.open(image_path).convert('RGB')\n",
    "# Preprocess the image\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "])\n",
    "input_tensor = transform(image).unsqueeze(0)\n",
    "\n",
    "# Perform object detection\n",
    "with torch.no_grad():\n",
    "    predictions = model(input_tensor)\n",
    "\n",
    "# Process the predictions\n",
    "pred_boxes = predictions[0]['boxes'].cpu().numpy()\n",
    "pred_scores = predictions[0]['scores'].cpu().numpy()\n",
    "pred_labels = predictions[0]['labels'].cpu().numpy()\n",
    "\n",
    "# Set a confidence threshold\n",
    "confidence_threshold = 0.5\n",
    "filtered_boxes = pred_boxes[pred_scores >= confidence_threshold]\n",
    "filtered_labels = pred_labels[pred_scores >= confidence_threshold]\n",
    "\n",
    "# Map the labels to class names\n",
    "pred_class_names = [coco_classes[label] for label in filtered_labels]\n",
    "\n",
    "# Visualize the results\n",
    "fig, ax = plt.subplots(1)\n",
    "ax.imshow(image)\n",
    "\n",
    "# Add bounding boxes to the image\n",
    "for box, label in zip(filtered_boxes, pred_class_names):\n",
    "    x1, y1, x2, y2 = box\n",
    "    rect = patches.Rectangle((x1, y1), x2 - x1, y2 - y1, linewidth=2, edgecolor='r', facecolor='none')\n",
    "    ax.add_patch(rect)\n",
    "    plt.text(x1, y1, f'{label}', bbox=dict(facecolor='white', alpha=0.5))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f66131-f5a1-4f1d-964c-4aff33cd7176",
   "metadata": {},
   "source": [
    "# Fish Detection with Faster R-CNN\n",
    "\n",
    "This section demonstrates how to load a custom-trained Faster R-CNN model using a ResNet-50 backbone on a Jetson device and use it for object detection. The example provided focuses on detecting objects in a fish dataset.\n",
    "\n",
    "## Sections\n",
    "\n",
    "1. Prerequisites\n",
    "2. Import Necessary Libraries\n",
    "3. Set Up the Dataset\n",
    "4. Load the Trained Model\n",
    "5. Prediction Function\n",
    "6. Visualize Prediction\n",
    "7. Example Usage\n",
    "8. Conclusion\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f37057f1-4765-4ba6-90c9-2a11996dca04",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from pycocotools.coco import COCO\n",
    "\n",
    "# Define the dataset path and classes\n",
    "dataset_path = '___' # FIX ME\n",
    "\n",
    "# Load classes from the dataset annotations\n",
    "coco = COCO(os.path.join(dataset_path, \"train\", \"_annotations.coco.json\"))\n",
    "categories = coco.cats\n",
    "classes = [i[1]['name'] for i in categories.items()]\n",
    "num_classes = len(classes)\n",
    "\n",
    "# Function to load the trained model\n",
    "def load_trained_model(model_path, num_classes):\n",
    "    # Initialize the model with the ResNet50 backbone\n",
    "    model = models.detection.fasterrcnn_resnet50_fpn(pretrained=False)\n",
    "    \n",
    "    # Replace the head with the appropriate number of classes\n",
    "    in_features = model.roi_heads.box_predictor.cls_score.in_features\n",
    "    model.roi_heads.box_predictor = models.detection.faster_rcnn.FastRCNNPredictor(in_features, num_classes)\n",
    "    \n",
    "    # Load the trained weights\n",
    "    model.load_state_dict(torch.load(model_path))\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "# Example usage\n",
    "model_path = os.path.expanduser('____') # FIX ME # Replace with your model's file path\n",
    "trained_model = load_trained_model(model_path, num_classes)\n",
    "\n",
    "# Function to perform inference\n",
    "def predict(image, model, device):\n",
    "    model.to(device)\n",
    "    image = [image.to(device)]\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        prediction = model(image)\n",
    "    return prediction\n",
    "\n",
    "# Example for visualizing the prediction\n",
    "def visualize_prediction(image, prediction, threshold=0.8):\n",
    "    from torchvision.utils import draw_bounding_boxes\n",
    "    import matplotlib.pyplot as plt\n",
    "\n",
    "    boxes = prediction[0]['boxes']\n",
    "    scores = prediction[0]['scores']\n",
    "    labels = prediction[0]['labels']\n",
    "\n",
    "    # Filter out low score boxes\n",
    "    keep = scores >= threshold\n",
    "    boxes = boxes[keep]\n",
    "    labels = labels[keep]\n",
    "    scores = scores[keep]\n",
    "\n",
    "    # Draw bounding boxes with labels and scores\n",
    "    class_names = [classes[i] for i in labels]\n",
    "    text = [(f\"{name}: {score:.2f}\") for name, score in zip(class_names, scores)]  # Combine label and score\n",
    "    drawn_image = draw_bounding_boxes(image.mul(255).byte(), boxes, text, width=4)\n",
    "\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    plt.imshow(drawn_image.permute(1, 2, 0).cpu())\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "# Assuming 'image' is a preprocessed tensor and 'device' is 'cpu' or 'cuda'\n",
    "# device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "# prediction = predict(image, trained_model, device)\n",
    "# visualize_prediction(image, prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201a9d88-fad6-4a9b-9bd6-03e448c22996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Assuming 'device' is 'cpu' or 'cuda'\n",
    "device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n",
    "\n",
    "# Replace with your image path\n",
    "image_path = '___' # FIX ME # Replace with your image path\n",
    "\n",
    "# Load and preprocess the image\n",
    "def preprocess_image(image_path):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    transform = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "    return transform(image)\n",
    "\n",
    "# Load and preprocess the image\n",
    "image = preprocess_image(image_path)\n",
    "\n",
    "# Perform inference\n",
    "prediction = predict(image, trained_model, device)\n",
    "\n",
    "# Visualize the prediction\n",
    "visualize_prediction(image, prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8618b10a-7e7e-49ff-b04e-2caeca397707",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "This notebook provides a template for loading and using a custom-trained Faster R-CNN model with a ResNet-50 backbone on Jetson devices. You can modify the code to suit your specific use case, such as adjusting the model architecture, dataset, or image preprocessing steps.\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

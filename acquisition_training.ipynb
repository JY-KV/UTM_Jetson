{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "12962b90",
   "metadata": {},
   "source": [
    "![alt](https://research.utm.my/wp-content/uploads/sites/26/2022/06/logo-300x122.png)\n",
    "# Center for Artificial Intelligence and Robotics\n",
    "#### Universiti Teknologi Malaysia\n",
    "\n",
    "\n",
    "### Data Acquisition Training\n",
    "\n",
    "*Author: Dr. Ibrahim, Azzam, Thaqif & Syahmi*\n",
    "\n",
    "**Resnet 50**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2d3afac7-721e-4122-93e2-ff519e09225c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import torch\n",
    "import torch.nn as nn  # All neural network modules, nn.Linear, nn.Conv2d, BatchNorm, Loss functions\n",
    "import torch.optim as optim  # For all Optimization algorithms, SGD, Adam, etc.\n",
    "import torchvision.transforms as transforms  # Transformations we can perform on our dataset\n",
    "import torchvision\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "from skimage import io\n",
    "from skimage.transform import rescale, resize, downscale_local_mean\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from PIL import Image\n",
    "from torchvision.models import resnet50\n",
    "from torch.utils.data import (\n",
    "    Dataset,\n",
    "    DataLoader,\n",
    ")  # Gives easier dataset management and creates mini batches\n",
    "from torchvision.datasets import ImageFolder\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "97d7f16b-8bfb-43b6-9452-04cfb9440273",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available:  True\n",
      "CUDA device count:  1\n",
      "CUDA device name:  Orin\n",
      "Device:  cuda\n"
     ]
    }
   ],
   "source": [
    "print(\"CUDA available: \", torch.cuda.is_available())\n",
    "print(\"CUDA device count: \", torch.cuda.device_count())\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA device name: \", torch.cuda.get_device_name(0))\n",
    "\n",
    "# Set device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(\"Device: \", device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84eb5cfc-830b-443e-96d4-4bf668792845",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transforms\n",
    "data_transforms = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baea60f4-ee4a-4dc7-ad2d-0375fd5d4db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_valid_file(path):\n",
    "    # Only accept files with valid extensions and ignore .ipynb_checkpoints directory\n",
    "    valid_extensions = {'.jpg', '.jpeg', '.png', '.ppm', '.bmp', '.pgm', '.tif', '.tiff', '.webp'}\n",
    "    return path.endswith(tuple(valid_extensions))\n",
    "\n",
    "# Directories for datasets #Replace wit your files directories\n",
    "train_dir = '___' # FIX ME # Replace with you dataset path\n",
    "val_dir = '___' # FIX ME # Replace with you dataset path\n",
    "\n",
    "# Load datasets using the specified method\n",
    "train_dataset = ImageFolder(root=train_dir, transform=data_transforms['train'], is_valid_file=is_valid_file)\n",
    "val_dataset = ImageFolder(root=val_dir, transform=data_transforms['val'], is_valid_file=is_valid_file)\n",
    "\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=8, shuffle=True)\n",
    "val_loader = DataLoader(dataset=val_dataset, batch_size=8, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d7c05d4-db27-4bd4-93bf-842d4016e0dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet50 model\n",
    "model = ______ # FIX ME # Replace wtih model name\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 3)  # Adjust the output layer to match the number of classes\n",
    "\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d5f811-c9b6-428d-9788-bb8a11e67589",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d1c43e-24bf-46d1-b0f7-2f59afffcead",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model with a scheduler\n",
    "num_epochs = 15\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        running_loss += loss.item() * inputs.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    # Step the scheduler\n",
    "    scheduler.step()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    epoch_acc = 100. * correct / total\n",
    "\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e980ed2a-828f-4771-8675-51dcd2965fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = outputs.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "\n",
    "val_acc = 100. * correct / total\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6909a084-b6c5-43d5-a9be-76a0373ca816",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model_save_path = os.path.expanduser('~/camera_classification.pth')\n",
    "torch.save(model.state_dict(), model_save_path)\n",
    "print(f\"Model saved to {model_save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d96796bd-bb69-4dfa-ba3d-b4c620420d74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define class labels #Replace wit your own class\n",
    "class_names = # FIX ME "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "119ea525-66ad-41e2-8856-6cb847b8d38c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction function\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def predict_image(model, image_path, class_names):\n",
    "    \"\"\"\n",
    "    Predict the class of an image using a trained model and display the image.\n",
    "    \n",
    "    Args:\n",
    "    - model (torch.nn.Module): Trained model for prediction.\n",
    "    - image_path (str): Path to the image file.\n",
    "    - class_names (list): List of class names.\n",
    "    \n",
    "    Returns:\n",
    "    - str: Formatted prediction result.\n",
    "    - dict: Probabilities for each class.\n",
    "    \"\"\"\n",
    "    # Transform to match the training preprocessing\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Load and preprocess the image\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image_tensor = transform(image)\n",
    "    image_tensor = image_tensor.unsqueeze(0)  # Add batch dimension\n",
    "\n",
    "    # Move the image to the device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "\n",
    "    # Make prediction\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(image_tensor)\n",
    "        probabilities = F.softmax(output, dim=1).cpu().numpy().squeeze()\n",
    "        predicted_idx = probabilities.argmax()\n",
    "    \n",
    "    predicted_class = class_names[predicted_idx]\n",
    "    confidence = probabilities[predicted_idx] * 100\n",
    "    result = f\"This image most likely belongs to {predicted_class} with a {confidence:.2f} percent confidence.\"\n",
    "    \n",
    "    # Display the image\n",
    "    plt.imshow(image)\n",
    "    plt.title(result)\n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "    \n",
    "    return result, dict(zip(class_names, probabilities))\n",
    "\n",
    "# Example usage:\n",
    "image_path = '___' # FIX ME # Replace with your image path\n",
    "result, probabilities = # FIX ME # Call the model\n",
    "print(result)\n",
    "print(f\"Probabilities: {probabilities}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

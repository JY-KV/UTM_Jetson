{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt](https://research.utm.my/wp-content/uploads/sites/26/2022/06/logo-300x122.png)\n",
    "# Center for Artificial Intelligence and Robotics\n",
    "#### Universiti Teknologi Malaysia\n",
    "\n",
    "\n",
    "### CNN Classification\n",
    "\n",
    "*Author: Dr. Ibrahim, Azzam, Thaqif & Syahmi*\n",
    "\n",
    "**MNIST Dataset**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_FwVLK-ChPXs"
   },
   "source": [
    "**Import Package**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "AcsCTfIl-m6K"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.datasets import MNIST\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jx9wosoNhXZ_"
   },
   "source": [
    "**Set Parameter & Download Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VBkjj_qD-swG",
    "outputId": "9b02c258-8b29-4754-bfcd-f2dcbea65816",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ./data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:11<00:00, 848965.98it/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ./data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 108322.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/train-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:06<00:00, 239544.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-images-idx3-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 404: Not Found\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 697387.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/MNIST/raw\n",
      "\n",
      "torch.Size([128, 1, 28, 28]) torch.Size([128])\n"
     ]
    }
   ],
   "source": [
    "# Parameters\n",
    "batch_size = 128\n",
    "num_classes = 10\n",
    "epochs = 2\n",
    "img_rows, img_cols = 28, 28\n",
    "\n",
    "# Define the data transform\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert PIL image or numpy array to tensor\n",
    "    transforms.Normalize((0.1307,), (0.3081,))  # Normalize the dataset\n",
    "])\n",
    "\n",
    "# Load the data\n",
    "train_dataset = MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "test_dataset = MNIST(root='./data', train=False, download=True, transform=transform)\n",
    "\n",
    "# Create DataLoader objects\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# Example of how to access the data\n",
    "for batch_idx, (data, target) in enumerate(train_loader):\n",
    "    print(data.shape, target.shape)  # Example output: torch.Size([128, 1, 28, 28]) torch.Size([128])\n",
    "    break\n",
    "\n",
    "# input_shape variable\n",
    "input_shape = (1, img_rows, img_cols)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "it4X9hafhjfa"
   },
   "source": [
    "**Normalize Dataset**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzn_gW24-vGQ",
    "outputId": "c57fbdae-0fd0-486e-a8e1-17b2f4e3c426"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch data shape: torch.Size([128, 1, 28, 28])\n",
      "Batch target shape: torch.Size([128])\n",
      "x_train shape: torch.Size([60000, 28, 28])\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# Example of how to access the data\n",
    "for data, target in train_loader:\n",
    "    print(f'Batch data shape: {data.shape}')  # Example output: torch.Size([128, 1, 28, 28])\n",
    "    print(f'Batch target shape: {target.shape}')  # Example output: torch.Size([128])\n",
    "    break\n",
    "\n",
    "# Print dataset shapes\n",
    "print(f'x_train shape: {train_dataset.data.shape}')\n",
    "print(f'{len(train_dataset)} train samples')\n",
    "print(f'{len(test_dataset)} test samples')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Uuc5K_BhqP7"
   },
   "source": [
    "**Create CNN Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hl-3lvzy-feX",
    "outputId": "fbe665f9-99ee-4021-96e8-8a4457ec54cd"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ConvNet(\n",
      "  (conv1): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (conv2): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
      "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (dropout1): Dropout(p=0.25, inplace=False)\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=9216, out_features=128, bias=True)\n",
      "  (dropout2): Dropout(p=0.5, inplace=False)\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Define the neural network architecture\n",
    "class ConvNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3)\n",
    "        self.pool = nn.MaxPool2d(kernel_size=2)\n",
    "        self.dropout1 = nn.Dropout(0.25)\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(64 * 12 * 12, 128)  # Adjust the size according to your input dimensions\n",
    "        self.dropout2 = nn.Dropout(0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.pool(x)\n",
    "        x = self.dropout1(x)\n",
    "        x = self.flatten(x)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)  # No softmax here\n",
    "        return x\n",
    "\n",
    "# Initialize the model, loss function, and optimizer\n",
    "model = ConvNet(num_classes=10)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dzU-qbkChxaF"
   },
   "source": [
    "**Compile Model and Train Model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pVphEMI--3sI",
    "outputId": "c52a9525-909f-45f5-8459-0fc52c22d0ab",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/2: 100%|██████████| 469/469 [00:53<00:00,  8.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Train Loss: 0.1196, Train Accuracy: 96.53%, Test Loss: 0.0435, Test Accuracy: 98.57%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/2: 100%|██████████| 469/469 [01:00<00:00,  7.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/2], Train Loss: 0.0750, Train Accuracy: 97.78%, Test Loss: 0.0358, Test Accuracy: 98.85%\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# Training the model\n",
    "num_epochs = 2\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model.to(device)\n",
    "\n",
    "# Lists to store metrics\n",
    "train_losses = []\n",
    "test_losses = []\n",
    "train_accuracies = []\n",
    "test_accuracies = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    # Wrap train_loader with tqdm for progress bar\n",
    "    for batch_idx, (data, target) in enumerate(tqdm(train_loader, desc=f'Epoch {epoch+1}/{num_epochs}')):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(data)\n",
    "        loss = criterion(outputs, target)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Update running loss\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        # Calculate accuracy\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += target.size(0)\n",
    "        correct += (predicted == target).sum().item()\n",
    "\n",
    "    # Compute average loss and accuracy for the epoch\n",
    "    train_loss = running_loss / len(train_loader)\n",
    "    train_accuracy = 100 * correct / total\n",
    "\n",
    "    train_losses.append(train_loss)\n",
    "    train_accuracies.append(train_accuracy)\n",
    "\n",
    "    # Evaluate on test data\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            outputs = model(data)\n",
    "            loss = criterion(outputs, target)\n",
    "            test_loss += loss.item()\n",
    "\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += target.size(0)\n",
    "            correct += (predicted == target).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader)\n",
    "    test_accuracy = 100 * correct / total\n",
    "\n",
    "    test_losses.append(test_loss)\n",
    "    test_accuracies.append(test_accuracy)\n",
    "\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Train Accuracy: {train_accuracy:.2f}%, Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n",
    "\n",
    "# Save the metrics\n",
    "torch.save({\n",
    "    'train_losses': train_losses,\n",
    "    'test_losses': test_losses,\n",
    "    'train_accuracies': train_accuracies,\n",
    "    'test_accuracies': test_accuracies\n",
    "}, 'model_metrics.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sh5nVAMch7df"
   },
   "source": [
    "**Plot Test Dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 428
    },
    "id": "2lnjcul6DPbH",
    "outputId": "977b2fb5-f651-4fb7-83ff-bbdae8f12b7f"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#print(x_test[500].shape)\n",
    "\n",
    "sample_index = 9999\n",
    "batch_size = test_loader.batch_size\n",
    "\n",
    "batch_index = sample_index // batch_size\n",
    "sample_index_in_batch = sample_index % batch_size\n",
    "\n",
    "for i, (data, target) in enumerate(test_loader):\n",
    "    if i == batch_index:\n",
    "        # Get the data tensor for the sample at index 500\n",
    "        sample_data = data[sample_index_in_batch].squeeze().cpu().numpy()\n",
    "        break\n",
    "else:\n",
    "    print(f\"Sample {sample_index} does not exist in the test dataset.\")\n",
    "\n",
    "\n",
    "# Show the test image\n",
    "# Plot the data tensor for the sample at index 500\n",
    "plt.imshow(sample_data, cmap='gray')\n",
    "plt.title(f'Sample {sample_index}')\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7m3UDpFyiEvz"
   },
   "source": [
    "**Predict, Save and Load Model**\n",
    "# Answer Question 1 - Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kMnhM9EzDJQS",
    "outputId": "d363a9ff-4709-4ade-8e54-7db578922a72"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class probabilities: [[0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    1.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    1.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    0.    0.    0.    1.   ]\n",
      " [0.998 0.    0.001 0.    0.    0.    0.    0.    0.001 0.   ]\n",
      " [0.    1.    0.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    1.    0.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    1.    0.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    1.    0.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    1.    0.    0.    0.    0.   ]\n",
      " [0.    0.    0.    0.    0.    0.    1.    0.    0.    0.   ]]\n",
      "Predicted class: 1\n"
     ]
    }
   ],
   "source": [
    "#data = x_test[500]\n",
    "#dt = np.reshape(data, [1, 28, 28, 1])\n",
    "\n",
    "# Predict dt from the trained model\n",
    "\n",
    "\n",
    "# Load the image and preprocess it\n",
    "sample_data_tensor = torch.tensor(sample_data, dtype=torch.float32).unsqueeze(0).unsqueeze(0).to(device)\n",
    "\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    ##Answer Here##\n",
    "    predicted_probs = torch.softmax(outputs, dim=1)\n",
    "\n",
    "# Convert the predicted probabilities tensor to a numpy array\n",
    "predicted_probs_np = predicted_probs.cpu().numpy()\n",
    "predicted_probs_np = np.round(predicted_probs_np, 3)\n",
    "\n",
    "\n",
    "# Get the predicted class (index with the highest probability)\n",
    "predicted_class = np.argmax(predicted_probs_np)\n",
    "print(\"Predicted class probabilities:\", predicted_probs_np)\n",
    "print(\"Predicted class:\", predicted_class)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CFCmg2SHHcX1"
   },
   "source": [
    "# Answer Question 2 - Save Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "p_rDg0pNCfx6"
   },
   "outputs": [],
   "source": [
    "# Save the model's state dictionary to your Google Drive folder\n",
    "\n",
    "# Specify the file path\n",
    "model_path = 'kv-model.pth'\n",
    "\n",
    "# Save the state dictionary\n",
    "torch.save(model.state_dict(), model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BAI7yNv1_qQ2",
    "outputId": "40153caf-2e24-4d4f-c2b3-27772c016c7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files in directory: ['data_dogcat', 'test_images', '.ipynb_checkpoints', 'ResNet50_plant_classification.pth', 'cat-dog.py', 'Pytorch_transfer_learning_Train_ResNet.ipynb', 'inference_trainedclassification.ipynb', 'model_metrics.pth', 'data', 'kv-model.pth', 'Pytorch_CNN_MNIST.ipynb', 'catdog_resnet50.pth']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# List files in the directory\n",
    "directory_path = os.getcwd()\n",
    "files = os.listdir(directory_path)\n",
    "print(\"Files in directory:\", files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dTTQlU4oId9G"
   },
   "source": [
    "\n",
    "# Answer Question 3 - Load Model\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2vSbn6w-Jlqc",
    "outputId": "ccb47494-4913-4cf0-c4da-2c1253cec82d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted class probabilities: [[0. 0. 0. 0. 0. 0. 1. 0. 0. 0.]]\n",
      "Predicted class: 6\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Load the model from your Google Drive folder\n",
    "model_path = 'kv-model.pth'\n",
    "\n",
    "# Initialize your model instance\n",
    "loaded_model = ConvNet()\n",
    "\n",
    "# Load the state dictionary from the file\n",
    "state_dict = torch.load(model_path)\n",
    "\n",
    "# Load the state dictionary into the model\n",
    "loaded_model.load_state_dict(state_dict)\n",
    "\n",
    "# Determine the device to use (GPU if available, otherwise CPU)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Move the model to the selected device\n",
    "loaded_model = loaded_model.to(device)\n",
    "\n",
    "# Move the input tensor to the selected device\n",
    "sample_data_tensor = sample_data_tensor.to(device)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "loaded_model.eval()\n",
    "\n",
    "# Perform inference\n",
    "with torch.no_grad():\n",
    "    outputs1 = loaded_model(sample_data_tensor)\n",
    "    predicted_probs1 = torch.softmax(outputs1, dim=1)\n",
    "\n",
    "# Convert the predicted probabilities tensor to a numpy array\n",
    "predicted_probs_np1 = predicted_probs1.cpu().numpy()\n",
    "predicted_probs_np1 = np.round(predicted_probs_np1, 3)\n",
    "\n",
    "# Get the predicted class (index with the highest probability)\n",
    "predicted_class1 = np.argmax(predicted_probs_np1)\n",
    "print(\"Predicted class probabilities:\", predicted_probs_np1)\n",
    "print(\"Predicted class:\", predicted_class1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "nRxifBjPAKPk"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/opt/jetson-inference/data/3. CNN Classification\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
